

- Training a Neural Network
- Activation Functions
	- Binary Classification : Sigmoid
	- Regression: Linear
	- 0 or positive : ReLU
- Why we need activation functions
- Multi-class classification
- Softmax
- Advanced Optimization
- Adam Algorithm: adjusts learning rate to optimize learning performance
- Additional Layer types : 
	- Convolutional Layer
- Backpropagation Algorithm
- 